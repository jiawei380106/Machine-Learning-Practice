{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT2101 Introduction to Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Goal\n",
    "\n",
    "In this notebook, we will explore **Decision Tree** including:\n",
    "* User-defined functions\n",
    "* Open-source package: `scikit-learn`\n",
    "\n",
    "For the **Decision Tree** method, you will:\n",
    "* Use numpy to write functions\n",
    "* Write binary recursive splitting functions\n",
    "* Write decision functions\n",
    "* Write pruning functions\n",
    "* Use open-source package to do classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt, log\n",
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Summary of Classification Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Tree\n",
    "A typical classification tree looks like this:\n",
    "<img src=\"https://cdn-images-1.medium.com/max/750/1*2jnsFCe0YmRjb8EvVAo93w.gif\" width=\"500\">\n",
    "\n",
    "#### Steps for Binary Splitting (E.g., Entropy)\n",
    "1. Compute the entropy for data-set;\n",
    "2. For every attribute/feature, calculate information gain for this attribute;\n",
    "3. Pick the feature with highest information gain;\n",
    "4. Repeat until we get the tree we desired;\n",
    "\n",
    "#### Entropy and Information Gain\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*EoWJ8bxc-iqBS-dF-XxsBA.jpeg\" width=\"900\">\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*wQjVzx7zCVb87htqk46vUA.jpeg\" width=\"900\">\n",
    "\n",
    "#### Alternative Criterion for Binary Splitting\n",
    "There are a few possible criteria we can use for selecting features and making the binary splits of classification decision tree:\n",
    "* Classification Error Rate\n",
    "* Gini Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Case: Kaggle Competition - Lending Club Loan Status\n",
    "### 3.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The file \"LoanStats_2018Q1.csv\" contains complete loan data for all loans issued through the 2018 Quarter-1, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the \"present\" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others.  <br/>\n",
    "Please see https://www.kaggle.com/wendykan/lending-club-loan-data/home.\n",
    "\n",
    "#### Attributes\n",
    "The dataset can be downloaded [here](https://www.lendingclub.com/info/download-data.action). Information on the columns and features can be found in data dictionary. A data dictionary is provided in a separate file \"LCDataDictionary.xlsx\".\n",
    "\n",
    "#### Goal\n",
    "Our goal is to show how to do binary splitting and tree pruning for a classification tree.\n",
    "\n",
    "#### Selected Features\n",
    "For the sake of simplicity, We only select 3 categorical variables as features. We will further transform these categorical variables into binary ones. You need to learn how to fit decision trees when features are continuous variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 1. Calculating entropy value of a given tree node with labels of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(sample_labels):\n",
    "    '''This function is used to calculate entropy value of a given tree node, in which there are samples with labels (0, 1) or (-1, 1).\n",
    "    Inputs:\n",
    "    1) sample_labels: Labels for samples in the current tree node, such as (1, 0, 0, 1, 0) or (1, -1, -1, 1, 0)\n",
    "    \n",
    "    Outputs:\n",
    "    1) entropy: Entropy value of labels in the current tree node.       \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Assert np.array\n",
    "    sample_labels = np.array(sample_labels)\n",
    "    \n",
    "    # What if sample_labels are empty\n",
    "    if sample_labels.size == 0:\n",
    "        return 0  \n",
    "    \n",
    "    # What if all the labels are the same\n",
    "    class_values = np.unique(sample_labels) # Sample labels/classes; Usually (0,1), sometimes (-1,1)\n",
    "    num0 = len(list(filter(lambda x:x==class_values[0], sample_labels))) # Number of samples with one label\n",
    "    num1 = len(list(filter(lambda x:x==class_values[1], sample_labels))) if class_values.size > 1 else 0 # Number of samples with another label\n",
    "    \n",
    "    if sample_labels.size == num0 or sample_labels.size == num1:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate entropy value      \n",
    "    p0 = num0 / (num0+num1) # Probability of class 0 labels\n",
    "    p1 = 1 - p0 # Probability of class 1 labels\n",
    "    \n",
    "    entropy = -(p0*log(p0,2) + p1*log(p1,2))    \n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 2. Calculating information gain when a given tree node is splitted by a given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(samples, output, feature):\n",
    "    '''This function is used to calculate information gain when a given tree node is splitted by a given feature.\n",
    "    Inputs:\n",
    "    1) samples: Samples in the current tree node before making split on the feature (Pandas Dataframe)\n",
    "    1) output: Name of the output column\n",
    "    2) feature: Name of the feature used to split the current tree node. Remember the features we selected in this case are binary.\n",
    "    \n",
    "    Outputs:\n",
    "    1) information_gain: How much reduction in entropy value if the current tree node is splitted by the feature \n",
    "    2) subsamples[0]: Data samples where feature values are one label (e.g., 0 or -1)\n",
    "    3) subsamples[1]: Data samples where feature values are another label (e.g., 1)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Split samples by feature values into subsamples\n",
    "    subsamples = defaultdict()\n",
    "    entropy_after = 0 # Entropy value after splitting\n",
    "    \n",
    "    for feature_value in np.unique(samples[output]):\n",
    "        subsamples[feature_value] = samples[samples[feature] == feature_value]\n",
    "        temp = subsamples[feature_value] # Store a temporary copy\n",
    "        p = len(temp) / len(samples) # Proportion of this subsample\n",
    "        entropy_after += p * entropy(temp[output])\n",
    "        \n",
    "    # Calculate information gain \n",
    "    information_gain = entropy(samples[output]) - entropy_after\n",
    "    \n",
    "    return (information_gain, subsamples[0], subsamples[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4199730940219749"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us have a test\n",
    "a = np.array([[1,0,0,1],[0,1,1,0],[1,1,1,1],[0,0,0,0],[1,1,0,0]])\n",
    "data = pd.DataFrame(a, columns=['x1','x2','x3','y'])\n",
    "info_gain(data, 'y', 'x1')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 3. Decide the best feature to split on: Using information gain and entropy as criterion\n",
    "1. Loop over each feature in the feature list;\n",
    "2. For each loop (feature f), split the data into 2 groups: In group 1 (left split), all samples' feature f has value 0. In group 2 (right split), all samples' feature f has value 1;\n",
    "3. Calculate the information gain for this split;\n",
    "4. If the information gain for this split using this feature is highest, then pick this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_feature_split(samples, output, features):\n",
    "    '''This function is used to determine the best feature to split based on maximized information gain.\n",
    "    Inputs:\n",
    "    1) samples: Samples in the current tree node before making split on the feature (Pandas Dataframe)\n",
    "    2) output: Name of the output column\n",
    "    3) features: A list of feature names\n",
    "    \n",
    "    Outputs:\n",
    "    1) best_feature: The best feature which is used to do binary splitting\n",
    "    2) best_left_split: Data samples where the best feature's values are 0\n",
    "    3) best_right_split: Data samples where the best feature's values are 1      \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Initialize best feature, best information gain value, best left/right split samples\n",
    "    best_feature = None \n",
    "    best_information_gain = 0\n",
    "    best_left_split = None\n",
    "    best_right_split = None    \n",
    "    \n",
    "    samples_row = float(len(samples)) # Number of rows in the data samples\n",
    "    \n",
    "    # Loop through features and find the best feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # Splitting the data samples\n",
    "        current_split = info_gain(samples, output, feature)\n",
    "        information_gain = current_split[0]\n",
    "        left_split = current_split[1]\n",
    "        right_split = current_split[2]\n",
    "        \n",
    "        # Check if this feature is better\n",
    "        if information_gain >= best_information_gain:\n",
    "            best_feature, best_information_gain, best_left_split, best_right_split = (feature, information_gain, left_split, right_split)\n",
    "    \n",
    "    return (best_feature, best_information_gain, best_left_split, best_right_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us have a test\n",
    "a = np.array([[1,0,0,1],[0,1,1,0],[1,1,1,1],[0,0,0,0],[1,1,0,0]])\n",
    "data = pd.DataFrame(a, columns=['x1','x2','x3','y'])\n",
    "best_feature_split(data, 'y', ['x1','x2','x3'])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 4. Build our classification tree and do pre-pruning\n",
    "We need to decide stopping conditions (i.e., pre-pruning):\n",
    "1. The samples' labels in the current node are the same (either 0 or 1);\n",
    "2. All the features have already been used for split;\n",
    "3. The current tree has already reached maximum depth **max_depth**;\n",
    "4. The number of samples in the current node is lower than minimum number **min_number**;\n",
    "5. The information gain for the current split is lower than a threshold **min_infogain** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopping Condition 1: The samples' labels in the current node are the same (either 0/-1 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_1(node_labels):\n",
    "    '''This function is used to verify whether stopping condition 1 is satisfied.\n",
    "    Inputs:\n",
    "    1) node_labels: The samples' labels in the current node\n",
    "    \n",
    "    Outputs:\n",
    "    1) True if they are all the same, False if otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # numpy array\n",
    "    node_labels = np.array(node_labels)\n",
    "    \n",
    "    # Empty labels\n",
    "    if len(node_labels) == 0:\n",
    "        return True\n",
    "    \n",
    "    if len(np.unique(node_labels)) == 1:\n",
    "        print(\"Stopping Condition 1: The samples' labels in the current node are the same (either 0/-1 or 1)\")\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopping Condition 2: All the features have already been used for split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_2(features):\n",
    "    '''This function is used to verify whether stopping condition 2 is satisfied.\n",
    "    Inputs:\n",
    "    1) features: A list of feature names\n",
    "    \n",
    "    Outputs:\n",
    "    1) True if the feature list is empty, False if otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if len(features) == 0 or features == None:\n",
    "        print(\"Stopping Condition 2: All the features have already been used for split\")\n",
    "        return True\n",
    "    else:\n",
    "        return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopping Condition 3: The current tree has already reached maximum depth **max_depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_3(tree_depth, max_depth):\n",
    "    '''This function is used to verify whether stopping condition 3 is satisfied.\n",
    "    Inputs:\n",
    "    1) tree_depth: The depth of the current tree\n",
    "    2) max_depth: Maximum tree depth\n",
    "    \n",
    "    Outputs:\n",
    "    1) True if the current depth reaches maximum depth, False if otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if tree_depth >= max_depth:\n",
    "        print(\"Stopping Condition 3: The current tree has already reached maximum depth\")\n",
    "        return True\n",
    "    else:\n",
    "        return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopping Condition 4: The number of samples in the current node is lower than minimum number **min_number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_4(samples, min_number):\n",
    "    '''This function is used to verify whether stopping condition 4 is satisfied.\n",
    "    Inputs:\n",
    "    1) samples: Data samples in the current node (Pandas DataFrame)\n",
    "    2) min_number: Minimum number of node size\n",
    "    \n",
    "    Outputs:\n",
    "    1) True if sample size is smaller than the minimum number, False if otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if samples.size <= min_number:\n",
    "        print(\"Stopping Condition 4: The number of samples in the current node is lower than minimum number\")\n",
    "        return True\n",
    "    else:\n",
    "        return False      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stopping Condition 5: The information gain for the current split is lower than a threshold **min_infogain** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_gain(samples, output, feature) -> information gain, left, right\n",
    "# best_feature_split(samples, output, features) -> feature, information gain, left, right\n",
    "def stop_5(info_gain, min_infogain):\n",
    "    '''This function is used to verify whether stopping condition 5 is satisfied.\n",
    "    Inputs:\n",
    "    1) info_gain: Information gain after this best split\n",
    "    2) min_infogain: Minimum information gain\n",
    "    \n",
    "    Outputs:\n",
    "    1) True if information gain after this best splitting is smaller than the minimum number, False if otherwise\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if info_gain <= min_infogain:\n",
    "        print(\"Stopping Condition 5: The information gain for the current split is lower than a threshold\")\n",
    "        return True\n",
    "    else:\n",
    "        return False      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build classification tree\n",
    "The data structure for the nested tree structure (including temporary tree nodes, and leaf nodes) is shown as:\n",
    "\n",
    "{ <br/>\n",
    "   'label': None for temporary node, or predicted label at the leaf node (e.g., \"Majority Voting\" criterion) for leaf node; <br/>\n",
    "   'left_tree': Left tree after the selected feature (=0 or -1) is splitted for temporary node, None for leaf node; <br/>\n",
    "   'right_tree': Right tree after the selected feature (=1) is splitted for temporary node, None for leaf node; <br/>\n",
    "   'best_feature': The feature that is selected to do binary split for temporary node, None for leaf node. <br/>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(output_labels):\n",
    "    '''This function is used to get predicted label based on \"Majority Voting\" criterion for the current leaf node.     \n",
    "    Inputs:\n",
    "    1) output_labels: Outputs (labels) in this leaf node, such as [1, 0, 0, 1, 1]\n",
    "    \n",
    "    Outputs:\n",
    "    1) prediction: Predicted label for this leaf node (e.g., 0/-1, or 1)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # numpy array\n",
    "    output_labels = np.array(output_labels)\n",
    "    \n",
    "    # Empty label\n",
    "    if output_labels.size == 0:\n",
    "        return None\n",
    "    \n",
    "    # Count output labels (0/-1 or 1)\n",
    "    values = np.unique(output_labels)\n",
    "    \n",
    "    if len(values) == 1:\n",
    "        return values[0]\n",
    "    else:\n",
    "        num0 = len(output_labels[output_labels == values[0]])\n",
    "        num1 = len(output_labels[output_labels == values[1]])\n",
    "        return values[1] if num1 >= num0 else values[0] # Prediction based on \"Majority Voting\" criterion   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationTree(samples, output, features, step, tree_depth, max_depth, min_number, min_infogain):\n",
    "    '''This function is used to build a classification tree in a recursive way.\n",
    "       Remember how you build a binary tree in the previous C++ and Data Structure courses).\n",
    "       \n",
    "    Inputs:\n",
    "    1) samples: Samples in the current tree node before making split on the feature (Pandas Dataframe)\n",
    "    2) output: Name of the output column\n",
    "    3) features: A list of feature names\n",
    "    4) step: The current binary split step\n",
    "    5) tree_depth: The depth of the current tree\n",
    "    6) max_depth: Maximum depth this tree can grow\n",
    "    7) min_number: Minimum number of node size\n",
    "    8) min_infogain: Minimum information gain\n",
    "    \n",
    "    Outputs:\n",
    "    1) tree_nodes: Nested tree nodes, which are stored and shown in nested dictionary type    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    current_features = features # Current feature list\n",
    "    labels = samples[output] # Output labels in the current tree node\n",
    "\n",
    "    print (\"----------------------------------------------------------------------------\")\n",
    "    print (\"----------------------------------------------------------------------------\")\n",
    "    print (\"Step %s: Current tree depth is %s. Current tree node has %s data points\" % (step, tree_depth, samples.size))\n",
    "    \n",
    "    # Verify whether stopping conditions 1-4 are satisfied. If satisfied, return a leaf_node\n",
    "    if stop_1(labels) or stop_2(current_features) or stop_3(tree_depth, max_depth) or stop_4(samples, min_number):\n",
    "        return {\n",
    "                'label': majority_vote(labels),\n",
    "                'left_tree': None,\n",
    "                'right_tree': None,\n",
    "                'best_feature': None            \n",
    "                }\n",
    "    \n",
    "    # If pass stopping conditions 1-4, then do best splitting\n",
    "    best_split = best_feature_split(samples, output, current_features)\n",
    "    best_feature, best_infogain, best_left, best_right = (best_split[0], best_split[1], best_split[2], best_split[3])\n",
    "    \n",
    "    # Verify whether stopping condition 5 is satisfied. If satisfied, return a leaf node\n",
    "    if stop_5(best_infogain, min_infogain):\n",
    "        return {\n",
    "                'label': majority_vote(labels),\n",
    "                'left_tree': None,\n",
    "                'right_tree': None,\n",
    "                'best_feature': None          \n",
    "            \n",
    "                } \n",
    "    \n",
    "    # If pass stopping condition 5, then move on\n",
    "    step += 1\n",
    "    print(\"Step %s: Binary split on %s. Size of Left and Right tree is (%s, %s)\" % (step, best_feature, len(best_left), len(best_right)))\n",
    "    current_features.remove(best_feature) # Remove this feature if this feature is used for split\n",
    "    \n",
    "    # Do binary split on left tree and right tree in a recursive way\n",
    "    left_split = ClassificationTree(best_left, output, current_features, step+1, tree_depth+1, max_depth, min_number, min_infogain)\n",
    "    right_split = ClassificationTree(best_right, output, current_features, step+1, tree_depth+1, max_depth, min_number, min_infogain)\n",
    "    \n",
    "    return {\n",
    "            'label': None,\n",
    "            'left_tree': left_split,\n",
    "            'right_tree': right_split,\n",
    "            'best_feature': best_feature        \n",
    "            \n",
    "            }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Cleaning\n",
    "We need to do some simple data cleaning work for original lend club loan data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Current', 'Fully Paid', 'Late (31-120 days)', 'Late (16-30 days)',\n",
       "       'Charged Off', 'In Grace Period', nan], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "loan_data = pd.read_csv(\"./LoanStats_2018Q1.csv\", low_memory=False, header=1)\n",
    "loan_data.head(n=10)\n",
    "loan_data[\"loan_status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107866, 145)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>url</th>\n",
       "      <th>desc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_plan_start_date</th>\n",
       "      <th>hardship_length</th>\n",
       "      <th>hardship_dpd</th>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <th>orig_projected_additional_accrued_interest</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>107864.000000</td>\n",
       "      <td>107864.000000</td>\n",
       "      <td>107864.000000</td>\n",
       "      <td>107864.000000</td>\n",
       "      <td>1.078640e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107602.000000</td>\n",
       "      <td>107864.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16147.942780</td>\n",
       "      <td>16147.942780</td>\n",
       "      <td>16143.857775</td>\n",
       "      <td>469.663151</td>\n",
       "      <td>7.854227e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.648209</td>\n",
       "      <td>0.223773</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3287.666667</td>\n",
       "      <td>66.680000</td>\n",
       "      <td>13.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10184.024938</td>\n",
       "      <td>10184.024938</td>\n",
       "      <td>10182.885389</td>\n",
       "      <td>289.224545</td>\n",
       "      <td>7.687436e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.795902</td>\n",
       "      <td>0.730417</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1821.483004</td>\n",
       "      <td>2.901189</td>\n",
       "      <td>4.163332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>30.120000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1387.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>254.560000</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2422.500000</td>\n",
       "      <td>65.005000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>14000.000000</td>\n",
       "      <td>389.360000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3458.000000</td>\n",
       "      <td>65.010000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22375.000000</td>\n",
       "      <td>637.840000</td>\n",
       "      <td>9.500000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4238.000000</td>\n",
       "      <td>67.520000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>1618.030000</td>\n",
       "      <td>8.365188e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5018.000000</td>\n",
       "      <td>70.030000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       member_id      loan_amnt    funded_amnt  funded_amnt_inv  \\\n",
       "count        0.0  107864.000000  107864.000000    107864.000000   \n",
       "mean         NaN   16147.942780   16147.942780     16143.857775   \n",
       "std          NaN   10184.024938   10184.024938     10182.885389   \n",
       "min          NaN    1000.000000    1000.000000      1000.000000   \n",
       "25%          NaN    8000.000000    8000.000000      8000.000000   \n",
       "50%          NaN   14000.000000   14000.000000     14000.000000   \n",
       "75%          NaN   22400.000000   22400.000000     22375.000000   \n",
       "max          NaN   40000.000000   40000.000000     40000.000000   \n",
       "\n",
       "         installment    annual_inc  url  desc            dti    delinq_2yrs  \\\n",
       "count  107864.000000  1.078640e+05  0.0   0.0  107602.000000  107864.000000   \n",
       "mean      469.663151  7.854227e+04  NaN   NaN      19.648209       0.223773   \n",
       "std       289.224545  7.687436e+04  NaN   NaN      21.795902       0.730417   \n",
       "min        30.120000  0.000000e+00  NaN   NaN       0.000000       0.000000   \n",
       "25%       254.560000  4.500000e+04  NaN   NaN      11.230000       0.000000   \n",
       "50%       389.360000  6.500000e+04  NaN   NaN      17.670000       0.000000   \n",
       "75%       637.840000  9.500000e+04  NaN   NaN      25.020000       0.000000   \n",
       "max      1618.030000  8.365188e+06  NaN   NaN     999.000000      20.000000   \n",
       "\n",
       "            ...         payment_plan_start_date  hardship_length  \\\n",
       "count       ...                             0.0              0.0   \n",
       "mean        ...                             NaN              NaN   \n",
       "std         ...                             NaN              NaN   \n",
       "min         ...                             NaN              NaN   \n",
       "25%         ...                             NaN              NaN   \n",
       "50%         ...                             NaN              NaN   \n",
       "75%         ...                             NaN              NaN   \n",
       "max         ...                             NaN              NaN   \n",
       "\n",
       "       hardship_dpd  hardship_loan_status  \\\n",
       "count           0.0                   0.0   \n",
       "mean            NaN                   NaN   \n",
       "std             NaN                   NaN   \n",
       "min             NaN                   NaN   \n",
       "25%             NaN                   NaN   \n",
       "50%             NaN                   NaN   \n",
       "75%             NaN                   NaN   \n",
       "max             NaN                   NaN   \n",
       "\n",
       "       orig_projected_additional_accrued_interest  \\\n",
       "count                                         0.0   \n",
       "mean                                          NaN   \n",
       "std                                           NaN   \n",
       "min                                           NaN   \n",
       "25%                                           NaN   \n",
       "50%                                           NaN   \n",
       "75%                                           NaN   \n",
       "max                                           NaN   \n",
       "\n",
       "       hardship_payoff_balance_amount  hardship_last_payment_amount  \\\n",
       "count                             0.0                           0.0   \n",
       "mean                              NaN                           NaN   \n",
       "std                               NaN                           NaN   \n",
       "min                               NaN                           NaN   \n",
       "25%                               NaN                           NaN   \n",
       "50%                               NaN                           NaN   \n",
       "75%                               NaN                           NaN   \n",
       "max                               NaN                           NaN   \n",
       "\n",
       "       settlement_amount  settlement_percentage  settlement_term  \n",
       "count           3.000000               3.000000         3.000000  \n",
       "mean         3287.666667              66.680000        13.333333  \n",
       "std          1821.483004               2.901189         4.163332  \n",
       "min          1387.000000              65.000000        10.000000  \n",
       "25%          2422.500000              65.005000        11.000000  \n",
       "50%          3458.000000              65.010000        12.000000  \n",
       "75%          4238.000000              67.520000        15.000000  \n",
       "max          5018.000000              70.030000        18.000000  \n",
       "\n",
       "[8 rows x 114 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-679f1a326edf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loan_data[\"loan_status\"].value_counts()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloan_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loan_status\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "loan_data[\"loan_status\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and output\n",
    "features = ['grade', 'term', 'home_ownership']       \n",
    "output = 'risky'\n",
    "loan_data = loan_data[loan_data['loan_status'] != 'Current']\n",
    "loan_data[output] = loan_data['loan_status'].map(lambda x: 1 if x in ['Late (31-120 days)', 'Late (16-30 days)', 'Charged Off'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>term</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>risky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B</td>\n",
       "      <td>36 months</td>\n",
       "      <td>OWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>D</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>D</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grade        term home_ownership  risky\n",
       "37      A   36 months           RENT      0\n",
       "83      C   36 months           RENT      0\n",
       "99      B   36 months            OWN      0\n",
       "112     D   36 months           RENT      0\n",
       "135     D   36 months           RENT      1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = loan_data[features+[output]]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical features to binary features\n",
    "grade_dummy = pd.get_dummies(dataset['grade'], prefix='grade')  \n",
    "term_dummy = pd.get_dummies(dataset['term'], prefix='term')\n",
    "home_ownership_dummy = pd.get_dummies(dataset['home_ownership'], prefix='home_ownership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6950, 17)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.join([grade_dummy, term_dummy, home_ownership_dummy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6950, 17)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna() # Remove all missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6950, 15)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update our features and output\n",
    "features = list(dataset.columns[2:])\n",
    "output = dataset.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Classification and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 0: Current tree depth is 0. Current tree node has 104250 data points\n",
      "Step 1: Binary split on grade_A. Size of Left and Right tree is (5628, 1322)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 2: Current tree depth is 1. Current tree node has 84420 data points\n",
      "Step 3: Binary split on home_ownership_MORTGAGE. Size of Left and Right tree is (3015, 2613)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 4: Current tree depth is 2. Current tree node has 45225 data points\n",
      "Step 5: Binary split on grade_B. Size of Left and Right tree is (2153, 862)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 6: Current tree depth is 3. Current tree node has 32295 data points\n",
      "Step 7: Binary split on grade_C. Size of Left and Right tree is (1110, 1043)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 8: Current tree depth is 4. Current tree node has 16650 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 8: Current tree depth is 4. Current tree node has 15645 data points\n",
      "Step 9: Binary split on term_ 60 months. Size of Left and Right tree is (753, 290)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 10: Current tree depth is 5. Current tree node has 11295 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 10: Current tree depth is 5. Current tree node has 4350 data points\n",
      "Step 11: Binary split on home_ownership_RENT. Size of Left and Right tree is (82, 208)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 12: Current tree depth is 6. Current tree node has 1230 data points\n",
      "Stopping Condition 3: The current tree has already reached maximum depth\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 12: Current tree depth is 6. Current tree node has 3120 data points\n",
      "Stopping Condition 3: The current tree has already reached maximum depth\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 6: Current tree depth is 3. Current tree node has 12930 data points\n",
      "Step 7: Binary split on term_ 36 months. Size of Left and Right tree is (172, 690)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 8: Current tree depth is 4. Current tree node has 2580 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 8: Current tree depth is 4. Current tree node has 10350 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 4: Current tree depth is 2. Current tree node has 39195 data points\n",
      "Step 5: Binary split on grade_G. Size of Left and Right tree is (2603, 10)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 6: Current tree depth is 3. Current tree node has 39045 data points\n",
      "Step 7: Binary split on grade_E. Size of Left and Right tree is (2408, 195)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 8: Current tree depth is 4. Current tree node has 36120 data points\n",
      "Step 9: Binary split on grade_F. Size of Left and Right tree is (2365, 43)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 10: Current tree depth is 5. Current tree node has 35475 data points\n",
      "Step 11: Binary split on grade_D. Size of Left and Right tree is (1748, 617)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 12: Current tree depth is 6. Current tree node has 26220 data points\n",
      "Stopping Condition 3: The current tree has already reached maximum depth\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 12: Current tree depth is 6. Current tree node has 9255 data points\n",
      "Stopping Condition 3: The current tree has already reached maximum depth\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 10: Current tree depth is 5. Current tree node has 645 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 8: Current tree depth is 4. Current tree node has 2925 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 6: Current tree depth is 3. Current tree node has 150 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 2: Current tree depth is 1. Current tree node has 19830 data points\n",
      "Step 3: Binary split on home_ownership_OWN. Size of Left and Right tree is (1094, 228)\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 4: Current tree depth is 2. Current tree node has 16410 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n",
      "----------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------\n",
      "Step 4: Current tree depth is 2. Current tree node has 3420 data points\n",
      "Stopping Condition 5: The information gain for the current split is lower than a threshold\n"
     ]
    }
   ],
   "source": [
    "# Suppose max_depth = 6; min_infogain=5e-4\n",
    "features = list(dataset.columns[2:])\n",
    "output = dataset.columns[1]\n",
    "tree_model = ClassificationTree(dataset, output, features, step=0, tree_depth=0, max_depth=6, min_number=5, min_infogain=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': None,\n",
       " 'left_tree': {'label': None,\n",
       "  'left_tree': {'label': None,\n",
       "   'left_tree': {'label': None,\n",
       "    'left_tree': {'label': 0,\n",
       "     'left_tree': None,\n",
       "     'right_tree': None,\n",
       "     'best_feature': None},\n",
       "    'right_tree': {'label': None,\n",
       "     'left_tree': {'label': 0,\n",
       "      'left_tree': None,\n",
       "      'right_tree': None,\n",
       "      'best_feature': None},\n",
       "     'right_tree': {'label': None,\n",
       "      'left_tree': {'label': 0,\n",
       "       'left_tree': None,\n",
       "       'right_tree': None,\n",
       "       'best_feature': None},\n",
       "      'right_tree': {'label': 0,\n",
       "       'left_tree': None,\n",
       "       'right_tree': None,\n",
       "       'best_feature': None},\n",
       "      'best_feature': 'home_ownership_RENT'},\n",
       "     'best_feature': 'term_ 60 months'},\n",
       "    'best_feature': 'grade_C'},\n",
       "   'right_tree': {'label': None,\n",
       "    'left_tree': {'label': 0,\n",
       "     'left_tree': None,\n",
       "     'right_tree': None,\n",
       "     'best_feature': None},\n",
       "    'right_tree': {'label': 0,\n",
       "     'left_tree': None,\n",
       "     'right_tree': None,\n",
       "     'best_feature': None},\n",
       "    'best_feature': 'term_ 36 months'},\n",
       "   'best_feature': 'grade_B'},\n",
       "  'right_tree': {'label': None,\n",
       "   'left_tree': {'label': None,\n",
       "    'left_tree': {'label': None,\n",
       "     'left_tree': {'label': None,\n",
       "      'left_tree': {'label': 0,\n",
       "       'left_tree': None,\n",
       "       'right_tree': None,\n",
       "       'best_feature': None},\n",
       "      'right_tree': {'label': 0,\n",
       "       'left_tree': None,\n",
       "       'right_tree': None,\n",
       "       'best_feature': None},\n",
       "      'best_feature': 'grade_D'},\n",
       "     'right_tree': {'label': 0,\n",
       "      'left_tree': None,\n",
       "      'right_tree': None,\n",
       "      'best_feature': None},\n",
       "     'best_feature': 'grade_F'},\n",
       "    'right_tree': {'label': 0,\n",
       "     'left_tree': None,\n",
       "     'right_tree': None,\n",
       "     'best_feature': None},\n",
       "    'best_feature': 'grade_E'},\n",
       "   'right_tree': {'label': 1,\n",
       "    'left_tree': None,\n",
       "    'right_tree': None,\n",
       "    'best_feature': None},\n",
       "   'best_feature': 'grade_G'},\n",
       "  'best_feature': 'home_ownership_MORTGAGE'},\n",
       " 'right_tree': {'label': None,\n",
       "  'left_tree': {'label': 0,\n",
       "   'left_tree': None,\n",
       "   'right_tree': None,\n",
       "   'best_feature': None},\n",
       "  'right_tree': {'label': 0,\n",
       "   'left_tree': None,\n",
       "   'right_tree': None,\n",
       "   'best_feature': None},\n",
       "  'best_feature': 'home_ownership_OWN'},\n",
       " 'best_feature': 'grade_A'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try different initial parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to predict new samples' labels. <br/>\n",
    "\n",
    "Remember our tree structure is like: <br/>\n",
    "{ <br/>\n",
    "   'label': None for temporary node, or predicted label at the leaf node (e.g., \"Majority Voting\" criterion) for leaf node; <br/>\n",
    "   'left_tree': Left tree after the selected feature (=0 or -1) is splitted for temporary node, None for leaf node; <br/>\n",
    "   'right_tree': Right tree after the selected feature (=1) is splitted for temporary node, None for leaf node; <br/>\n",
    "   'best_feature': The feature that is selected to do binary split for temporary node, None for leaf node. <br/>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(new_sample, train_tree):   \n",
    "    '''This function is used to predict the label of one new sample.\n",
    "    Inputs:\n",
    "    1) new_sample: A new sample, we would like to predict its label (Pandas DataFrame)\n",
    "    2) train_tree: The classification tree we have just trained\n",
    "    \n",
    "    Outputs:\n",
    "    1) predict_label: The predicted label for this new sample  \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # If move to the leaf node\n",
    "    if train_tree['best_feature']==None:\n",
    "        return train_tree['label']\n",
    "    \n",
    "    # If still stay at temporary node\n",
    "    else:\n",
    "        # Find the value of the best feature in the current node\n",
    "        # If value is 0, then go to left tree\n",
    "        # If value is 1, then go to right tree\n",
    "        # Remember what your have learned in Data Structure course, about binary tree\n",
    "        best_feature = train_tree['best_feature']\n",
    "        return predict_label(new_sample, train_tree['left_tree']) if new_sample[best_feature]==0 else predict_label(new_sample, train_tree['right_tree'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to learn partial and apply function. They are powerful.\n",
    "from functools import partial\n",
    "prediction = partial(predict_label, train_tree=tree_model)\n",
    "predicted_labels = dataset.apply(lambda x: prediction(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate predicted_labels into our dataset\n",
    "dataset['prediction'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>risky</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>home_ownership_ANY</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>home_ownership_OWN</th>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  risky  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  \\\n",
       "0     37      0        1        0        0        0        0        0   \n",
       "1     83      0        0        0        1        0        0        0   \n",
       "2     99      0        0        1        0        0        0        0   \n",
       "3    112      0        0        0        0        1        0        0   \n",
       "4    135      1        0        0        0        1        0        0   \n",
       "\n",
       "   grade_G  term_ 36 months  term_ 60 months  home_ownership_ANY  \\\n",
       "0        0                1                0                   0   \n",
       "1        0                1                0                   0   \n",
       "2        0                1                0                   0   \n",
       "3        0                1                0                   0   \n",
       "4        0                1                0                   0   \n",
       "\n",
       "   home_ownership_MORTGAGE  home_ownership_OWN  home_ownership_RENT  \\\n",
       "0                        0                   0                    1   \n",
       "1                        0                   0                    1   \n",
       "2                        0                   1                    0   \n",
       "3                        0                   0                    1   \n",
       "4                        0                   0                    1   \n",
       "\n",
       "   prediction  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignments: \n",
    "* Write functions to use `Gini index` and `misclassification error rate` as metrics for binary splitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Open-Source Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a break and let us use open-source package to run decision tree models. <br/>\n",
    "Use `Scikit-learn`to make classification trees and make predictions: http://scikit-learn.org/stable/modules/tree.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update our features and output\n",
    "features = list(dataset.columns[2:])\n",
    "output = dataset.columns[1]\n",
    "\n",
    "# Split dataset to do validation\n",
    "X = dataset[features]\n",
    "y = dataset[output]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on train data\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree_model = decision_tree.fit(X_train, y_train)\n",
    "decision_tree_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted labels for test data\n",
    "y_pred = decision_tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "print cm\n",
    "print TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of decision tree model\n",
    "print \"Accuracy: \", accuracy_score(y_test, y_pred)\n",
    "print \"Sensitivity: \", recall_score(y_test, y_pred)\n",
    "print \"Precision: \", precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to calculate:\n",
    "1. Accuracy\n",
    "2. Misclassification rate\n",
    "3. Precision\n",
    "4. Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Get predicted scores Pr(y=1): Used as thresholds for calculating TP Rate and FP Rate\n",
    "score = decision_tree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score) # fpr: FP Rate, tpr: TP Rate, thresholds: Pr(y=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision tree\n",
    "# Remember you should install package graphviz first\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(decision_tree_model, out_file=None, feature_names=features, class_names=output, \n",
    "                                filled=True, rounded=True, special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in .pdf \n",
    "graph.render(\"Lending Club Loan Status\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignments: \n",
    "* Use Titanic data (“train.csv”); Fit the model using `scikit-learn` with different metrics (e.g., information gain, gini index)\n",
    "* Observe and report the differences (e.g., best features for splitting, tree structure, performance, etc.)\n",
    "* There are no right or wrong answers. Don't worry. Just report what you've seen. \n",
    "\n",
    "**Note:** You need to do simple data cleaning by yourself, such as binarizing output variable \"survived\", and transforming categorical variables to dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Questions (Just think about them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 What if features are continuous?\n",
    "### 5.2 What if output is continuous? \n",
    "* Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 References\n",
    "\n",
    "[1] Jason Brownlee, 2018, [Machine Learning Algorithms from Scratch with Python](https://machinelearningmastery.com/machine-learning-algorithms-from-scratch/). <br/>\n",
    "[2] Peter Harrington, 2012. Machine Learning in Action. Shelter Island, NY: Manning Publications Co."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
