{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT2101 Introduction to Numpy and Pandas\n",
    "## Goal: Understanding how to do data cleaning in python\n",
    "### Reference Book: \"Python for Data Analysis\"\n",
    "Note: The codes and datasets for this reference book is released [here](https://resources.oreilly.com/examples/0636920023784/).\n",
    "![alt text](https://covers.oreillystatic.com/images/0636920023784/lrg.jpg \"book.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Install Numpy and Pandas\n",
    "* Go to the links for [numpy](http://www.numpy.org/) and [pandas](https://pandas.pydata.org/)\n",
    "* Follow the instructions and install the packages\n",
    "* Import two packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Simple Guide on Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 1D Array\n",
    "* Transform list to Numpy array\n",
    "* Indexing and Slicing\n",
    "* Basic Operations\n",
    "* Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform List to Numpy Array\n",
    "a = [1, 3, 9]\n",
    "A = np.array(a)\n",
    "\n",
    "print \"List a: \", a, type(a)\n",
    "print \"Array A: \", A, type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Attributes of Numpy Array\n",
    "print \"Data type of array A: \", A.dtype\n",
    "print \"Size of array A: \", A.size\n",
    "print \"Dimension of array A: \", A.ndim\n",
    "print \"Shape of array A: \", A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [1.1, 2.3, 4.5, 5.1, 7.9]\n",
    "B = np.array(b)\n",
    "\n",
    "print \"Data type of array B: \", B.dtype\n",
    "print \"Size of array B: \", B.size\n",
    "print \"Dimension of array B: \", B.ndim\n",
    "print \"Shape of array B: \", B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and Slicing\n",
    "print \"The 1st element of Array A is: \", A[0]\n",
    "print \"The 3rd element of Array B is: \", B[4]\n",
    "\n",
    "print \"Get a slice of Array B: \", B[1:3]\n",
    "\n",
    "# Change Values\n",
    "A[1] = 10\n",
    "print \"The new Array A is: \", A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations\n",
    "u = np.array([1,3,5])\n",
    "v = np.array([2,4,6])\n",
    "z1 = u + v\n",
    "z2 = 2 * u\n",
    "z3 = u * v\n",
    "z4 = np.dot(u, v)\n",
    "z5 = v + 1\n",
    "\n",
    "print \"u + v = \", z1\n",
    "print \"2 * u = \", z2\n",
    "print \"u * v = \", z3\n",
    "print \"Dot product of u and v is: \", z4\n",
    "print \"v + 1 = \", z5\n",
    "print \"Mean of u is: \", u.mean()\n",
    "print \"Mean of v is: \", v.mean()\n",
    "print \"Maximum value of u is: \", u.max()\n",
    "print \"Maximum value of v is: \", v.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Functions\n",
    "c = np.array([1, np.pi, np.pi/2])\n",
    "sin_c = np.sin(c)\n",
    "\n",
    "print \"Sin of c is: \", sin_c\n",
    "\n",
    "# Generate a sequence of 5 numbers from -2 to 2\n",
    "print np.linspace(-2, 2, 5)\n",
    "\n",
    "# Generate a sequence from 1 to 20\n",
    "print np.arange(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Visualization using matplotlib\n",
    "# Note: Do not forget installing \"matplotlib\" package before import it\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Generate a sequence of 100 numbers\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 2D Array\n",
    "* Transform list to Numpy array\n",
    "* Indexing and Slicing\n",
    "* Basic Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform List to 2D Array\n",
    "A = np.array([[10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33]])\n",
    "\n",
    "print \"Size of Array A: \", A.size\n",
    "print \"Dimension of Array A: \", A.ndim\n",
    "print \"Shape of Array A: \", A.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and Slicing\n",
    "print \"The element of Row 1 Column 3 is: \", A[0][2]\n",
    "print \"The element of Row 3 Column 4 is: \", A[2][3]\n",
    "\n",
    "print \"The elements of Row 2, 3 and Column 4: \", A[1:3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations\n",
    "X = np.array([[11, 12], [21, 22]])\n",
    "Y = np.array([[1, 3], [2, 4]])\n",
    "\n",
    "print \"X + Y = \", X + Y\n",
    "print \"2 * X = \", 2 * X\n",
    "print \"X * Y = \", X * Y\n",
    "print \"2D Array multiplication: XY = \", np.dot(X, Y)\n",
    "print \"Transpose of 2D Array is: \", X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Functions\n",
    "from numpy.random import randn\n",
    "\n",
    "# Generate a 2D Array with elements drawn from N(0, 1)\n",
    "print randn(2 ,3)\n",
    "\n",
    "# Generate 2D Array with Dimension (3, 4) and elements all zero\n",
    "print np.zeros((3,4))\n",
    "\n",
    "# Functions: Mean, Sum, Max, Min, ..., etc.\n",
    "arr = randn(5, 4) # normally-distributed data\n",
    "print \"arr is: \", arr\n",
    "print arr.mean()\n",
    "print np.mean(arr)\n",
    "print arr.sum()\n",
    "print arr.mean(axis=1)\n",
    "print arr.sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: More numpy functions can be found at https://docs.scipy.org/doc/numpy-1.14.5/reference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform list and Array to Numpy Matrix\n",
    "* Basic Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform List and Array to Matrix\n",
    "a = [[4,7],[2,6]]\n",
    "A = np.array(a)\n",
    "mat_A = np.mat(A)\n",
    "\n",
    "print \"List: \", a\n",
    "print \"Array: \", A\n",
    "print \"Matrix: \", mat_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functions of Matrix\n",
    "print \"Transpose Matrix: \", mat_A.T\n",
    "print \"Inverse Matrix: \", mat_A.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Working with Data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Understanding basic data structures in pandas\n",
    "* Loading dataset and transform to pandas dataframe\n",
    "* Simple guide on data cleaning\n",
    "* Summary statistics\n",
    "* Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Structure: Series and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data structure: Series\n",
    "a = [1.1, 2.2, 3.3, 4.4]\n",
    "a_series = pd.Series(a)\n",
    "\n",
    "print \"Transform List into Series: \", a_series\n",
    "print \"Values in the series: \", a_series.values\n",
    "print \"Type of values in the series: \", type(a_series.values) \n",
    "print \"Index of series: \", a_series.index\n",
    "\n",
    "b = {'one':1, 'two':2, 'three':3}\n",
    "print \"Transform dictionary into Series: \", pd.Series(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and Slicing\n",
    "a_series = pd.Series(a, index=[\"a\",\"b\",\"c\",\"d\"])\n",
    "print \"Index of series is: \", a_series.index\n",
    "print \"Index b is: \", a_series[\"b\"]\n",
    "\n",
    "a_series['c'] = 5.5\n",
    "print \"Index a, c, d is: \", a_series[['a','c','d']].values\n",
    "print \"Values which are larger than 3: \", a_series[a_series>3].values\n",
    "print \"Whether series has index b: \", 'b' in a_series\n",
    "print \"Whether series has index f: \", 'f' in a_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Useful Functions and Attributes\n",
    "c = pd.Series(b, index=['one','two','three','five'])\n",
    "print c\n",
    "print \"Which element is null value: \", c.isnull()\n",
    "print \"Which element is not null: \", c.notnull()\n",
    "\n",
    "# Naming the Series and its index\n",
    "c.name = 'numerical value'\n",
    "c.index.name = 'character value'\n",
    "print c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data structure: DataFrame\n",
    "# Very similar to R's data.frame\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "frame = pd.DataFrame(data)\n",
    "print frame\n",
    "print \"Shape of DataFrame is: \", frame.shape\n",
    "print \"Change the order of variables: \"\n",
    "print pd.DataFrame(data, columns=['year', 'state', 'pop'])\n",
    "print \"Change the index of variables: \"\n",
    "print pd.DataFrame(data, columns=['year', 'state', 'pop','new_variable'], index=['1','2','3','4','5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some attributes of DataFrame\n",
    "print \"Columns of dataframe: \", frame.columns\n",
    "print \"Get variable year from dataframe: \", frame['year']\n",
    "print \"Another way to get variable year from dataframe: \", frame.year\n",
    "print \"Get multiple variables: \", frame[['year','pop']]\n",
    "\n",
    "frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop','new_variable'])\n",
    "print \"Get first 3 rows, first 2 columns of DataFrame: \", frame2.iloc[:3, :2]\n",
    "print \"Get 1st row of DataFrame: \", frame2.iloc[0]\n",
    "print \"Get 3rd row, 3rd column of DataFrame: \", frame2.iloc[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-wise and Column-wise operations\n",
    "\n",
    "# Modify values of variables\n",
    "frame2.new_variable = 15\n",
    "print frame2\n",
    "\n",
    "frame2['new_variable'] = pd.Series([17, 19, 21], index=[0,2,4])\n",
    "print frame2\n",
    "\n",
    "frame2.iloc[2, 2] = 10\n",
    "print frame2\n",
    "\n",
    "# Delete columns\n",
    "frame3 = pd.DataFrame(data, columns=['year', 'state', 'pop','new_variable'])\n",
    "del frame3['new_variable']\n",
    "print \"Drop columns: \", frame3\n",
    "\n",
    "# Or\n",
    "frame3 = pd.DataFrame(data, columns=['year', 'state', 'pop','new_variable'])\n",
    "print \"Another way to drop columns: \", frame3.drop(['new_variable'], axis=1)\n",
    "\n",
    "# Delete rows\n",
    "print \"Delete 4th row: \", frame3.drop([3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important operations and functions\n",
    "frame4 = pd.DataFrame(np.random.randn(4, 3), columns=list('abc'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "print \"frame4 is: \", frame4 \n",
    "\n",
    "# Transpose of DataFrame\n",
    "print \"Transpose of DataFrame: \", frame.T\n",
    "\n",
    "# Apply function: .apply()  .applymap()  .map()\n",
    "# Superpowerful !!!\n",
    "print \"The range of each column is: \", frame4.apply(lambda x: x.max()-x.min(), axis=0)\n",
    "print \"Keep 2 decimals for each element: \", frame4.applymap(lambda x: \"%.2f\" % x)\n",
    "print \"Keep 3 decimals for column c: \", frame4['c'].map(lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe\n",
    "frame4 = pd.DataFrame(np.random.randn(4, 3), columns=list('abc'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "print frame4\n",
    "print \"Sort dataframe by column b and a: \", frame4.sort_index(by=['b', 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values and value counts\n",
    "obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])\n",
    "print obj.unique()\n",
    "print obj.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data\n",
    "data = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan], [np.nan, 3, 4], [np.nan, 6.5, 3.]])\n",
    "print data\n",
    "\n",
    "# Find missing data\n",
    "print \"Whether dataframe has missing values: \", data.isnull()\n",
    "\n",
    "# Drop missing values\n",
    "clean = data.dropna()\n",
    "print \"After dropping missing values: \", clean\n",
    "\n",
    "# Fillin missing values\n",
    "fill = data.fillna(0)\n",
    "print \"After filling missing values: \", fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Indexing\n",
    "data = pd.Series(np.random.randn(10), index=[['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 2, 3, 1, 2, 2, 3]])\n",
    "print data\n",
    "print \"Index b and c: \", data['b':'c']\n",
    "\n",
    "print \"Unstack the hierarchical indexing data: \", data.unstack()\n",
    "print \"Stack dataframe into hierarchical indexing data: \", frame4.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load dataset into pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Iris)\n",
    "\n",
    "Attribute Information:\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "5. class:\n",
    " * Iris Setosa\n",
    " * Iris Versicolour\n",
    " *  Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \"*.txt\" or \"*.csv\" into python\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "colnames = ['sepal_length','sepal_width','petal_length','petal_width','class']\n",
    "data.iloc[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "data.columns = colnames\n",
    "print data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation table\n",
    "print data.corr()\n",
    "\n",
    "# How many unique classes\n",
    "print data['class'].unique()\n",
    "print data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Cleaning: Transform, Merge, Reshape, Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and Join Tables\n",
    "table1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'data1': range(6)})\n",
    "table2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'], 'data2': range(5)})\n",
    "\n",
    "print \"Merging Table1 and Table2: \"\n",
    "print pd.merge(table1, table2)\n",
    "print \"Merge Table1 and Table2 on column key: \"\n",
    "print pd.merge(table1, table2, on='key')\n",
    "print \"Outer Join Table1 and Table2: \"\n",
    "print pd.merge(table1, table2, how='outer')\n",
    "print \"Left Join Table1 and Table2: \"\n",
    "print pd.merge(table1, table2, how='left')\n",
    "print \"Inner Join Table1 and Table2: \"\n",
    "print pd.merge(table1, table2, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating tables\n",
    "table1 = pd.DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])\n",
    "table2 = pd.DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])\n",
    "print pd.concat([table1, table2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data from \"long\" to \"wide\"\n",
    "%pwd  #This is an Ipython magic command\n",
    "data = pd.read_csv('./macrodata.csv')\n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='date')\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data.to_records(), columns=pd.Index(['realgdp', 'infl', 'unemp'], name='item'), index=periods.to_timestamp('D', 'end'))\n",
    "data.rename(columns={'infl':'inflation', 'unemp':'unemployment'}, inplace=True)\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From wide data to long data\n",
    "ldata = data.stack().reset_index().rename(columns={0: 'value'})\n",
    "print ldata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape long data to wide data\n",
    "wdata = ldata.pivot('date', 'item', 'value')\n",
    "print wdata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated rows\n",
    "data = pd.DataFrame({'k1': ['one'] * 3 + ['two'] * 4, 'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "print data\n",
    "print \"Whether this row is duplicated: \"\n",
    "print data.duplicated()\n",
    "print \"After dropping duplicated rows: \"\n",
    "print data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "data = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'], 'x': range(6)})\n",
    "print \"Original data: \"\n",
    "print data\n",
    "print \"Create dummies: \"\n",
    "print data.join(pd.get_dummies(data['key'], prefix='key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Operations\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "colnames = ['sepal_length','sepal_width','petal_length','petal_width','class']\n",
    "data.columns = colnames\n",
    "\n",
    "print data.head(5)\n",
    "\n",
    "df = data.groupby(['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby: mean, size, sum, max, min,...,etc.\n",
    "print \"Mean by class: \"\n",
    "print df.mean()\n",
    "\n",
    "print \"Size for class: \"\n",
    "print df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interate over groups\n",
    "for name, group in df:\n",
    "    print \"name is: \", name\n",
    "    print \"group is: \", group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby with function\n",
    "people = pd.DataFrame(np.random.randn(5, 5), columns=['a', 'b', 'c', 'd', 'e'], index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])\n",
    "people.iloc[2:3, people.columns.get_indexer(['b','c'])] = np.nan # Add a few NA values\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.groupby(len).sum() # group by the length of the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = ['one', 'one', 'one', 'two', 'two']\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation \n",
    "df = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'], \n",
    "                'key2' : ['one', 'two', 'one', 'two', 'one'],\n",
    "                'data1' : np.random.randn(5),\n",
    "                'data2' : np.random.randn(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['key1'])\n",
    "grouped.agg(lambda x: x.max()-x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.describe().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.agg(['mean', 'std', lambda x: x.max()-x.min()]).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add names to different aggregation functions\n",
    "grouped.agg([('Average value','mean'), ('Standard deviation','std'), ('Range',lambda x: x.max()-x.min())]).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform values\n",
    "# Example: Use mean values to replace the original values\n",
    "print \"Before transforming: \"\n",
    "print df\n",
    "print \"After transforming: \"\n",
    "print df.groupby(['key1']).transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are familiar with SQL, you may check the comparison between `Pandas` and `SQL` [here](https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: More information about **Pandas** can be found [here](https://pandas.pydata.org/pandas-docs/stable/tutorials.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
