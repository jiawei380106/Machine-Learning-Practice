{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BT2101 Tutorial 1: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt, log\n",
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate entropy with 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_two_only(sample_labels):\n",
    "    '''Takes in labels for one attribute. E.g. if we are splitting by gender, input would be vactor for males\n",
    "    1) sample_labels: Labels for samples in the current tree node, such as (1, 0, 0, 1, 0) or (1, -1, -1, 1, 0)\n",
    "    Outputs:\n",
    "    1) entropy: Entropy value of labels in the current tree node.       \n",
    "    '''\n",
    "    \n",
    "    # Assert np.array\n",
    "    sample_labels = np.array(sample_labels)\n",
    "    \n",
    "    # What if sample_labels are empty\n",
    "    if sample_labels.size == 0:\n",
    "        return 0  \n",
    "    \n",
    "    # What if all the labels are the same\n",
    "    class_values = np.unique(sample_labels) # Sample labels/classes; Usually (0,1), sometimes (-1,1)\n",
    "    num0 = len(list(filter(lambda x:x==class_values[0], sample_labels))) # Number of samples with one label\n",
    "    num1 = len(list(filter(lambda x:x==class_values[1], sample_labels))) if class_values.size > 1 else 0 # Number of samples with another label\n",
    "    \n",
    "    if sample_labels.size == num0 or sample_labels.size == num1:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate entropy value      \n",
    "    p0 = num0 / (num0+num1) # Probability of class 0 labels\n",
    "    p1 = 1 - p0 # Probability of class 1 labels\n",
    "    \n",
    "    entropy = -(p0*log(p0,2) + p1*log(p1,2))    \n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General function to calculate entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(sample_labels):\n",
    "    \"\"\"Input: A vector of sample labels e.g. [A,B,A,C,C,C,A,B,B,A,C,B,A,A]. \n",
    "       This input has to be for a particular segment of the attribute we are splitting on.\n",
    "       e.g. if splitting on gender attribute, the vector will be the labels for all males. OR all females. etc   \n",
    "       Output: A number between 0 and 1, the entropy\"\"\"\n",
    "    \n",
    "    # Assert that it it a numpy array\n",
    "    sample_labels = np.array(sample_labels)\n",
    "    \n",
    "    # Return 0 if empty array\n",
    "    if sample_labels.size == 0:\n",
    "        return 0\n",
    "    \n",
    "    class_values = np.unique(sample_labels)\n",
    "    entropy = 0  # initialize entropy\n",
    "    \n",
    "    # iterate over every class and get the proportion. From there, add to entropy using formula.\n",
    "    for label in class_values:\n",
    "        number_of_instances = len(list(filter(lambda x:x==label, sample_labels)))\n",
    "        if number_of_instances == 0:   # if no instances of this class, continue\n",
    "            continue\n",
    "            \n",
    "        proportion = number_of_instances/len(sample_labels)\n",
    "        entropy -= proportion*log(proportion,2)\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually calculate entropy for genders (experimental section - can ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read and prepare data\n",
    "df = pd.read_csv('titanic_final.csv')\n",
    "#df[\"Survived\"] = pd.Categorical(df[\"Survived\"]).codes   # converts labels into numerical categories\n",
    "\n",
    "overall_entropy = entropy(df[\"Survived\"])  # overall entropy of dataset\n",
    "\n",
    "### GENDER\n",
    "#split by gender (attribute)\n",
    "male = df[df[\"Gender\"] == \"Male\"]\n",
    "female = df[df[\"Gender\"] == \"Female\"]\n",
    "\n",
    "# get the entropies\n",
    "entropy_male = entropy(male[\"Survived\"])\n",
    "entropy_female = entropy(female[\"Survived\"])\n",
    "weighted_entropy = (entropy_male*len(male) + entropy_female*len(female))/len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(df, selected_feature, label, method):\n",
    "    \"\"\"df: Takes in the whole dataframe\n",
    "       Selected Feature: Name of the column which we want to split on\n",
    "       Label: Name of column which contains the labels\n",
    "       method: The function we are using. eg entropy or gini_index. These are in fact functions.\n",
    "       This function outputs a tuple (weighted_entropy, info_gain)\"\"\"\n",
    "\n",
    "    initial_measure = method(df[label])    # calculate overall entropy/ gini-index of dataframe\n",
    "    attribute_segments = df[selected_feature].unique()   # stores a list of all segments within chosen attribute eg.[male, female]\n",
    "    \n",
    "    weighted_measure = 0   # initialise weighted entropy/ gini-index\n",
    "    \n",
    "    for segment in attribute_segments:\n",
    "        data_for_segment = df[df[selected_feature] == segment]\n",
    "        labels_for_segment = data_for_segment[label]\n",
    "        measure_for_this = method(labels_for_segment)\n",
    "        weighted_measure += measure_for_this * len(data_for_segment)\n",
    "    \n",
    "    weighted_measure /= len(df)\n",
    "    info_gain = initial_measure - weighted_measure\n",
    "    \n",
    "    return (weighted_measure, info_gain)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate information gain for all attributes using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Class : (0.8675277182987636, 0.10342287615590495)\n",
      "Passenger Class : (0.8172018848211989, 0.15374870963346965)\n",
      "Gender : (0.5619639695247292, 0.4089866249299394)\n",
      "No of Siblings or Spouses on Board : (0.7834701673945229, 0.18748042706014567)\n",
      "No of Parents or Children on Board : (0.9654839523229165, 0.005466642131752075)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_final.csv\")\n",
    "attributes = df.columns[1:-1]\n",
    "\n",
    "# print out the weighted entropy and info gain for each attribute.\n",
    "for attribute in attributes:\n",
    "    print(attribute, \":\", calc_info_gain(df, attribute, df.columns[-1], entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General function to calculate Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(sample_labels):\n",
    "    \"\"\"Input: A vector of sample labels e.g. [A,B,A,C,C,C,A,B,B,A,C,B,A,A]. \n",
    "       This input has to be for a particular segment of the attribute we are splitting on.\n",
    "       e.g. if splitting on gender attribute, the vector will be the labels for all males. OR all females. etc   \n",
    "       Output: The gini index for this split\"\"\"\n",
    "    \n",
    "    # Assert that it it a numpy array\n",
    "    sample_labels = np.array(sample_labels)\n",
    "    \n",
    "    # Return 0 if empty array\n",
    "    if sample_labels.size == 0:\n",
    "        return 0\n",
    "    \n",
    "    class_values = np.unique(sample_labels)\n",
    "    intermediate_sum = 0  # initialize 1 - (gini index)\n",
    "    \n",
    "    # iterate over every class and get the proportion. From there, add to entropy using formula.\n",
    "    for label in class_values:\n",
    "        number_of_instances = len(list(filter(lambda x:x==label, sample_labels)))\n",
    "            \n",
    "        proportion = number_of_instances/len(sample_labels)\n",
    "        intermediate_sum += proportion**2\n",
    "    \n",
    "    return 1 - intermediate_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate information gain for all attributes using Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Class : (0.4277777777777778, 0.05222222222222217)\n",
      "Passenger Class : (0.38055555555555554, 0.09944444444444445)\n",
      "Gender : (0.22962962962962957, 0.2503703703703704)\n",
      "No of Siblings or Spouses on Board : (0.3576252723311547, 0.12237472766884527)\n",
      "No of Parents or Children on Board : (0.4763285024154589, 0.0036714975845411058)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_final.csv\")\n",
    "attributes = df.columns[1:-1]\n",
    "\n",
    "# print out the weighted entropy and info gain for each attribute.\n",
    "for attribute in attributes:\n",
    "    print(attribute, \":\", calc_info_gain(df, attribute, df.columns[-1], gini_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
